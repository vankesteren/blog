<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Erik-Jan van Kesteren" />


<title>Bootstrap</title>

<script src="bootstrap_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="bootstrap_files/bootstrap-3.3.5/css/journal.min.css" rel="stylesheet" />
<script src="bootstrap_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="bootstrap_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="bootstrap_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="bootstrap_files/navigation-1.1/tabsets.js"></script>
<script src="bootstrap_files/navigation-1.1/codefolding.js"></script>
<link href="bootstrap_files/highlightjs-1.1/default.css" rel="stylesheet" />
<script src="bootstrap_files/highlightjs-1.1/highlight.js"></script>
<!DOCTYPE HTML>
<link href="../img/favicon.png" rel="shortcut icon" type="image/png">
<link href="../img/favicon.png" rel="apple-touch-icon" />

<script type="application/json" class="js-hypothesis-config">
  {
    "showHighlights": false
  }
</script>
<script src="https://hypothes.is/embed.js" async></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>






<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Bootstrap</h1>
<h4 class="author"><em>Erik-Jan van Kesteren</em></h4>

</div>


<div id="back-to-index" class="section level3">
<h3><a href="../index.html">Back to index</a></h3>
</div>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>The word “bootstrap” comes from an old story about a hero - Baron Munchausen - who is riding around on his horse in a forest and suddenly gets stuck in a swamp. He screams for help but there is no one around who hears his voice! Luckily our hero does not give up and gets a great idea: “what if I just pull myself out of this swamp?”. He grabs the <em>straps</em> of his <em>boots</em> and pulls himself loose. Fantastic - he just invented bootstrapping.</p>
<img src="bootstrap_files/munchausen.svg" width="40%" style="display:block; margin-left:auto; margin-right:auto"></img>
<center>
<em>Baron Munchausen ponytailing out of another swamp.</em><a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>
</center>
<p><br/></p>
<p>Physics-defying stories aside, bootstrapping has become a common term for something seemingly impossible or counterintuitive. In this blogpost I will try to generate an intuition for the properties of <em>statistical bootstrapping</em> - resampling from your data to approximate resampling from a population.</p>
</div>
<div id="the-population" class="section level2">
<h2>The population</h2>
<p>In order to explain bootstrapping, we need to generate an example. Let’s assume we want to know the average height of all the people in the Netherlands. With the power of <code>R</code> we can easily generate a population of 17104879 people (according to CBS, the amount of registered inhabitants of the Netherlands as per the creation of this post<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>). The Dutch are just about the tallest people on the planet, where the men are 180,7 centimeters tall, on average<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>.</p>
<p>Here is some more information about my population. For the sake of simplicity let’s assume that all inhabitants are actually men (which would be a disaster). The tallest Dutch man is 223 centimeters<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> (which is very tall) and the shortest Dutch man is ridiculously hard to find on the internet. I have an intuition that it is further away from the mean of 180.7, which implies some negative skewness, but that’s not what this post is about so let’s also assume we have a non-skewed normal distribution.</p>
<p>After some fiddling with the standard deviation variable, I simulated the following population:</p>
<pre class="r"><code># generate population data
set.seed(3665364)
pop &lt;- rnorm(17104879, mean = 180.7, sd = 7.5)

# plot the distribution
hist(pop, freq = FALSE, ylim = c(0, 0.06), xlim = c(120, 240), axes = FALSE, 
    breaks = 30, xlab = &quot;&quot;, ylab = &quot;&quot;, main = &quot;&quot;, col = &quot;#1E90FF88&quot;, border = &quot;#00008B&quot;)
polygon(density(pop, from = 130, to = 230), cex = 2, col = &quot;#1E90FF44&quot;, border = &quot;#00008B&quot;, 
    lwd = 2)
abline(v = 180.7, col = &quot;white&quot;, lwd = 2)
axis(1, at = c(130, 155, 180, 205, 230))
mtext(&quot;Population height distribution&quot;, side = 3, line = 1, cex = 1.8)
mtext(&quot;N = 17104879&quot;, side = 2, line = 0)
mtext(&quot;Height in cm&quot;, side = 1, line = 3)</code></pre>
<p><img src="bootstrap_files/figure-html/popsvg-1.svg" style="display: block; margin: auto;" /></p>
<p>Let’s look how tall the tallest man from the hypothetical all-men Netherlands is, along with some other statistics!</p>
<pre class="r"><code>cat(&quot; Statistics about the population:\n&quot;, &quot;--------------------------------\n&quot;, 
    &quot;The shortest person is &quot;, min(pop), &quot; cm tall.\n&quot;, &quot;Mean height is &quot;, mean(pop), 
    &quot; cm.\n&quot;, &quot;Median height is &quot;, median(pop), &quot; cm.\n&quot;, &quot;The 5th and 95th percentiles are &quot;, 
    quantile(pop, probs = c(0.05, 0.95)), &quot;cm.\n&quot;, &quot;The tallest person is &quot;, 
    max(pop), &quot; cm tall.&quot;)</code></pre>
<pre><code>##  Statistics about the population:
##  --------------------------------
##  The shortest person is  142.0121  cm tall.
##  Mean height is  180.6979  cm.
##  Median height is  180.698  cm.
##  The 5th and 95th percentiles are  168.3612 193.0287 cm.
##  The tallest person is  222.2139  cm tall.</code></pre>
<p>That seems close enough to something I’d consider a population.</p>
</div>
<div id="the-set-up" class="section level2">
<h2>The set-up</h2>
<p>Normally, when we want to estimate some population parameter such as the mean height, we cannot measure all persons. Therefore, we create a <em>representative sample</em> of persons from this population that we <em>can</em> measure. The size of our sample (<span class="math inline">\(N\)</span>) should depend on how precise we want our final estimate to be - the <em>standard error</em> of a statistic depends directly on the number of persons in our sample. For the mean, the standard error is usually calculated as follows:</p>
<p><span class="math display">\[ se_\bar{x} = \frac{\hat{\sigma}}{\sqrt{N}}\text{, where } \hat{\sigma} = \sqrt{\frac{1}{N-1}\sum_{i=1}^N(x_i-\bar{x})^2} \]</span></p>
<p>With increasing <span class="math inline">\(N\)</span>, the <span class="math inline">\(\hat{\sigma}\)</span> becomes smaller, and the <span class="math inline">\(se_\bar{x}\)</span> becomes smaller as well. In words: with a larger sample comes an increase in precision (a reduction in error).</p>
<p>We can display the precision in the form of <em>confidence intervals</em> (CI). A <span class="math inline">\(p\%\)</span> CI about an estimate indicates the area in which upon infinitely repeated sampling the TRUE parameter lies <span class="math inline">\(p\%\)</span> of the time. In other words, if we would redo our experiment infinite amount of times, a 95% confidence interval will <em>cover</em> the true parameter in 95% of the replications.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p>
<p>In real life, there is of course no such thing as infinite resampling; we only sample once and use the CI as an indication of precision. Let’s look at how the precision of the mean estimate increases as we take larger samples from the above population.</p>
<pre class="r"><code># randomly sample from population
small &lt;- sample(pop, 20)
medium &lt;- sample(pop, 100)
large &lt;- sample(pop, 1000)

# calculate means
means &lt;- mean(small)
meanm &lt;- mean(medium)
meanl &lt;- mean(large)

# calculate standard errors
ses &lt;- sd(small)/sqrt(length(small))
sem &lt;- sd(medium)/sqrt(length(medium))
sel &lt;- sd(large)/sqrt(length(large))

# calculate confidence intervals
CIs &lt;- c(means - 1.96 * ses, means + 1.96 * ses)
CIm &lt;- c(meanm - 1.96 * sem, meanm + 1.96 * sem)
CIl &lt;- c(meanl - 1.96 * sel, meanl + 1.96 * sel)

# initialise plot
plot(0, xlim = c(170, 190), ylim = c(0, 4), bty = &quot;L&quot;, xlab = &quot;Height in cm&quot;, 
    ylab = &quot;&quot;, axes = F, cex = 1.3, main = &quot;Effect of sampling on CI&quot;)
axis(1, cex = 1.3)

# horizontal lines
lines(CIl, y = c(1, 1), lwd = 2)
lines(CIm, y = c(2, 2), lwd = 2)
lines(CIs, y = c(3, 3), lwd = 2)

# points
points(c(means, meanm, meanl), c(3, 2, 1), bg = &quot;black&quot;, pch = 24)

# vertical lines
lines(c(CIl[1], CIl[1]), c(0.9, 1.1), lwd = 2)
lines(c(CIl[2], CIl[2]), c(0.9, 1.1), lwd = 2)
lines(c(CIm[1], CIm[1]), c(1.9, 2.1), lwd = 2)
lines(c(CIm[2], CIm[2]), c(1.9, 2.1), lwd = 2)
lines(c(CIs[1], CIs[1]), c(2.9, 3.1), lwd = 2)
lines(c(CIs[2], CIs[2]), c(2.9, 3.1), lwd = 2)

# true mean
abline(v = mean(pop), lwd = 2, lty = 3)

# text
text(y = c(1, 2, 3), x = 172, labels = c(&quot;N = 1000&quot;, &quot;N = 100&quot;, &quot;N = 20&quot;), pos = 4, 
    cex = 1.3)</code></pre>
<p><img src="bootstrap_files/figure-html/prec-1.svg" style="display: block; margin: auto;" /></p>
<p>As you can see, the CI from each sample covers the true population value in this case. We can create these confidence intervals because we know the <em>sampling distribution</em> of the mean - the distribution of the mean that arises upon repeated sampling. For means of a normally distributed population, the sampling distribution is the familiar Student’s <em>t</em>-distribution. We use the probability density to determine our 95% CI (the <code>1.96</code> in the code above).</p>
<p>But what if we don’t exactly know what the sampling distribution is? For example, what happens if we do not have a normally distributed population? It turns out there is another way of generating CIs.</p>
</div>
<div id="the-bootstrap" class="section level2">
<h2>The bootstrap</h2>
<p>The bootstrap has these steps:</p>
<ol style="list-style-type: decimal">
<li>approximate the sampling distribution by taking the mean of n repeated samples with replacement from your original sample.</li>
</ol>
<p>Huh? Only one step? Is it that simple?</p>
<p>Yes:</p>
<pre class="r"><code># Let&#39;s bootstrap 10000 times!
mean_sampling_distribution &lt;- numeric(10000)
for (i in 1:10000) {
    bootstrap_sample &lt;- sample(medium, replace = T)
    mean_sampling_distribution[i] &lt;- mean(bootstrap_sample)
}

opt &lt;- par(mar = c(5, 1, 4, 1))
hist(mean_sampling_distribution, freq = FALSE, xlim = c(175, 187), axes = FALSE, 
    breaks = 30, xlab = &quot;Height in cm&quot;, ylab = &quot;&quot;, main = &quot;Bootstrap Sampling Distribution&quot;, 
    col = &quot;#1E90FF88&quot;, border = &quot;#00008B&quot;)
axis(1, at = c(175, 178, 181, 184, 187))</code></pre>
<p><img src="bootstrap_files/figure-html/boot-1.svg" style="display: block; margin: auto;" /></p>
<p>Great! Now we have an <em>empirical</em> sampling distribution. What do we do now in order to get an estimate of our precision in the form of a confidence interval? That is simple too: sort the means attained from the bootstrap samples from low to high, and look at the 2.5th and 97.5th percentile. This yields a 95% bootstrap CI!</p>
<pre class="r"><code>CIbootstrap &lt;- quantile(mean_sampling_distribution, probs = c(0.025, 0.975))

# plot
plot(0, xlim = c(170, 190), ylim = c(0, 3), bty = &quot;L&quot;, xlab = &quot;Height in cm&quot;, 
    ylab = &quot;&quot;, axes = F, cex = 1.3, main = &quot;Bootstrap CI&quot;)
axis(1, cex = 1.3)

# original CI
lines(CIm, y = c(2, 2), lwd = 2)
lines(c(CIm[1], CIm[1]), c(1.9, 2.1), lwd = 2)
lines(c(CIm[2], CIm[2]), c(1.9, 2.1), lwd = 2)

# bootstrap CI
lines(CIbootstrap, y = c(1, 1), lwd = 2, col = &quot;dark green&quot;)
lines(c(CIbootstrap[1], CIbootstrap[1]), c(0.9, 1.1), lwd = 2, col = &quot;dark green&quot;)
lines(c(CIbootstrap[2], CIbootstrap[2]), c(0.9, 1.1), lwd = 2, col = &quot;dark green&quot;)

# true mean
abline(v = mean(pop), lwd = 2, lty = 3)

# text
text(y = c(1, 2), x = 172, labels = c(&quot;Bootstrap CI&quot;, &quot;Theoretical CI&quot;), pos = 4, 
    cex = 1.3)

# points
points(c(meanm, meanm), c(2, 1), bg = c(&quot;black&quot;, &quot;dark green&quot;), col = c(&quot;black&quot;, 
    &quot;dark green&quot;), pch = 24)</code></pre>
<p><img src="bootstrap_files/figure-html/bootCI-1.svg" style="display: block; margin: auto;" /></p>
<p>As you can see, that’s indeed very close to the original theoretical CI.</p>
</div>
<div id="the-advantage" class="section level2">
<h2>The advantage</h2>
<p>The advantage of this method is that this does not require the researcher to know the exact form of the sampling distribution. We can now create CIs (and thereby an estimate of precision) for nearly any statistic that we think about, such as (a) the fifth percentile, (b) the median, (c) the ninety-ninth percentile, (d) this completely arbitrary statistic called <em>van kesteren measure</em> that I just came up with: <span class="math display">\[\hat{k} = \bar{x}\cdot\frac{1}{N}\sum_{i=1}^N |x_i^\frac{1}{3}-\sqrt{\text{median}(x)}|\]</span></p>
<p>Probably there are analytical solutions to the sampling distributions of these measures (and I think it is likely that they have been derived at some point in the 1940s) but I don’t know them so I’ll bootstrap:</p>
<pre class="r"><code>vkmeasure &lt;- function(x) {
    return(mean(x)/length(x) * sum(abs(x^(1/3) - sqrt(median(x)))))
}

perc5 &lt;- median &lt;- perc99 &lt;- vkmeas &lt;- numeric(10000)

for (i in 1:10000) {
    bootstrap_sample &lt;- sample(large, replace = T)  # bootstrap from large this time
    perc5[i] &lt;- quantile(bootstrap_sample, probs = 0.05)
    median[i] &lt;- median(bootstrap_sample)
    perc99[i] &lt;- quantile(bootstrap_sample, probs = 0.99)
    vkmeas[i] &lt;- vkmeasure(bootstrap_sample)
}

par(mfrow = c(2, 2))
hist(perc5, freq = FALSE, axes = FALSE, breaks = 30, xlab = &quot;Height in cm&quot;, 
    ylab = &quot;&quot;, main = &quot;Fifth percentile&quot;, col = &quot;#1E90FF88&quot;, border = &quot;#00008B&quot;)
axis(1)
hist(median, freq = FALSE, axes = FALSE, breaks = 30, xlab = &quot;Height in cm&quot;, 
    ylab = &quot;&quot;, main = &quot;Median&quot;, col = &quot;#1E90FF88&quot;, border = &quot;#00008B&quot;)
axis(1)
hist(perc99, freq = FALSE, axes = FALSE, breaks = 30, xlab = &quot;Height in cm&quot;, 
    ylab = &quot;&quot;, main = &quot;Ninety-ninth percentile&quot;, col = &quot;#1E90FF88&quot;, border = &quot;#00008B&quot;)
axis(1)
hist(vkmeas, freq = FALSE, axes = FALSE, breaks = 30, xlab = &quot;vk units&quot;, ylab = &quot;&quot;, 
    main = &quot;van Kesteren measure&quot;, col = &quot;#1E90FF88&quot;, border = &quot;#00008B&quot;)
axis(1)</code></pre>
<p><img src="bootstrap_files/figure-html/bootCI2-1.svg" style="display: block; margin: auto;" /></p>
<p>As you can see, the distributions are a little strange, mainly due to the first three measures being more unstable and dependent on sample characteristics. In the end, however, we have magically done away with a problem - that of distributional assumptions - by pulling ourselves up from our bootstraps, not unlike our friend Baron Munchausen! Fantastic! Or is it?</p>
</div>
<div id="the-downside" class="section level2">
<h2>The downside</h2>
<p>There is one major point I have not yet touched upon: in our simulation we assumed that each person <span class="math inline">\(i\)</span> in our population has the same probability of being sampled - the <em>sampling probability</em> <span class="math inline">\(\pi_i\)</span>. In practice this is rarely the case: we have to deal with a sampling procedure. Let’s design a sampling procedure!</p>
<p>I assume that we do not have a complete register of all hypothetical Dutch men. Instead, I define two (strange) sampling strategies:</p>
<ol style="list-style-type: decimal">
<li><p>I go to the most busy street in the city centre on a Sunday during midday and I take a picture. With intensely cool facial recognition software I identify the people on this picture and send them an e-card to invite them to participate in my study. The problem is that I see a disproportionately large amount of tall people because they stick out from the mass. This is called undercoverage of the population.</p></li>
<li><p>I go to a primary school at the border of the Netherlands and Belgium and I measure the height of every person I see. Obviously, these are mostly kids (and a few teachers). There is an additional problem with this: 30% of the kids at the school are Belgian, which is not the population we are interested in. The Belgians do not come from our same tall-person distribution but probably from a distribution with a much much lower mean height! This phenomenon is called overcoverage.</p></li>
</ol>
<p>To see what happens in each of these cases, we should define some sampling probabilities.</p>
<pre class="r"><code># for the first case tall people are more likely to be selected (prob sum to
# 1)
popsorted &lt;- sort(pop)
probs1 &lt;- sort(pop - min(pop))/sum(pop - min(pop))


# for the second case we need to make the belgian distribution.
belgianpop &lt;- rnorm(n = 11190846, mean = 170.2, sd = 7.5)

# we will sample mostly children, who are all below 150 cm tall. There are
# 23 children for every adult:
dutchprob2 &lt;- ifelse(pop &lt; 150, 23, 1)
dutchprob2 &lt;- dutchprob2/sum(dutchprob2)  # sum to 1

belgiprob2 &lt;- ifelse(belgianpop &lt; 150, 23, 1)
belgiprob2 &lt;- belgiprob2/sum(belgiprob2)  # sum to 1

# and let&#39;s assume that there are 30% belgians and 70% dutch at the school
popbenl &lt;- c(pop, belgianpop)
probs2 &lt;- c(dutchprob2 * 0.7, belgiprob2 * 0.3)


opt &lt;- par(mfrow = c(2, 1), mar = c(4, 2, 0, 2), oma = c(0, 0, 3, 0))
# plot the distribution
hist(pop, freq = FALSE, ylim = c(0, 0.06), xlim = c(120, 240), axes = FALSE, 
    breaks = 30, xlab = &quot;&quot;, ylab = &quot;&quot;, main = &quot;&quot;, col = &quot;#1E90FF88&quot;, border = &quot;#00008B&quot;)
polygon(density(pop, from = 130, to = 230), cex = 2, col = &quot;#1E90FF44&quot;, border = &quot;#00008B&quot;, 
    lwd = 2)
abline(v = 180.7, col = &quot;white&quot;, lwd = 2)
axis(1, at = c(130, 155, 180, 205, 230))

mtext(&quot;Population height distribution&quot;, side = 3, line = 1, cex = 1.8, outer = TRUE)
mtext(&quot;Frequency&quot;, side = 2, line = 0, col = &quot;#00008B&quot;)
par(new = T)
plot(popsorted[c(1, length(probs1))], probs1[c(1, length(probs1))], xlim = c(130, 
    230), type = &quot;l&quot;, axes = FALSE, ylab = &quot;&quot;, xlab = &quot;&quot;, col = &quot;white&quot;)
polygon(x = c(popsorted[c(1, length(probs1))], popsorted[length(probs1)]), y = c(probs1[c(1, 
    length(probs1))], 0), border = &quot;#006400&quot;, col = &quot;#32CD3288&quot;)
mtext(&quot;Selection probability&quot;, side = 4, line = 0, col = &quot;#006400&quot;)

hist(popbenl, freq = FALSE, ylim = c(0, 0.06), xlim = c(120, 240), axes = FALSE, 
    breaks = 45, xlab = &quot;&quot;, ylab = &quot;&quot;, main = &quot;&quot;, col = &quot;#1E90FF88&quot;, border = &quot;#00008B&quot;)
polygon(density(popbenl, from = 130, to = 230), cex = 2, col = &quot;#1E90FF44&quot;, 
    border = &quot;#00008B&quot;, lwd = 2)
abline(v = mean(popbenl), col = &quot;white&quot;, lwd = 2)
axis(1, at = c(130, 155, 180, 205, 230))

mtext(&quot;Frequency&quot;, side = 2, line = 0, col = &quot;#00008B&quot;)
mtext(&quot;Height in cm&quot;, side = 1, line = 3)
mtext(&quot;Selection probability&quot;, side = 4, line = 0, col = &quot;#006400&quot;)</code></pre>
<p><img src="bootstrap_files/figure-html/sampprobs-1.svg" style="display: block; margin: auto;" /></p>
<p>Now let’s take our regular samples out of these sampling frames</p>
<pre class="r"><code># Let&#39;s sample from these sampling frames!
sample1 &lt;- sample(popsorted, size = 100, prob = probs1)
sample2 &lt;- sample(popbenl, size = 100, prob = probs2)

par(mfrow = c(2, 1))
# plot the distribution
hist(sample1, freq = FALSE, ylim = c(0, 0.06), xlim = c(130, 230), axes = FALSE, 
    breaks = 30, xlab = &quot;&quot;, ylab = &quot;&quot;, main = &quot;&quot;, col = &quot;#1E90FF88&quot;, border = &quot;#00008B&quot;)
polygon(density(sample1, from = 130, to = 230), cex = 2, col = &quot;#1E90FF44&quot;, 
    border = &quot;#00008B&quot;, lwd = 2)
abline(v = 180.7, col = &quot;white&quot;, lwd = 2)
axis(1, at = c(130, 155, 180, 205, 230))
mtext(&quot;Sample 1 histogram&quot;, side = 3, line = 1, cex = 1.8)
mtext(&quot;N = 100&quot;, side = 2, line = 0)
mtext(&quot;Height in cm&quot;, side = 1, line = 3)

hist(sample2, freq = FALSE, ylim = c(0, 0.06), xlim = c(130, 230), axes = FALSE, 
    breaks = 45, xlab = &quot;&quot;, ylab = &quot;&quot;, main = &quot;&quot;, col = &quot;#1E90FF88&quot;, border = &quot;#00008B&quot;)
polygon(density(sample2, from = 130, to = 230), cex = 2, col = &quot;#1E90FF44&quot;, 
    border = &quot;#00008B&quot;, lwd = 2)
abline(v = 180.7, col = &quot;white&quot;, lwd = 2)
axis(1, at = c(130, 155, 180, 205, 230))
mtext(&quot;Sample 2 histogram&quot;, side = 3, line = 1, cex = 1.8)
mtext(&quot;N = 100&quot;, side = 2, line = 0)
mtext(&quot;Height in cm&quot;, side = 1, line = 3)</code></pre>
<p><img src="bootstrap_files/figure-html/coverage-errors-1.svg" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<div id="back-to-index-1" class="section level3">
<h3><a href="../index.html">Back to index</a></h3>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Source: <a href="http://en.citizendium.org/wiki/Image:Dore-Munchausen-pull.jpg" class="uri">http://en.citizendium.org/wiki/Image:Dore-Munchausen-pull.jpg</a><a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Source: <a href="https://www.cbs.nl/nl-nl/visualisaties/bevolkingsteller" class="uri">https://www.cbs.nl/nl-nl/visualisaties/bevolkingsteller</a> as per the writing of this post.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Source: <a href="https://is.gd/cbsdata" class="uri">https://is.gd/cbsdata</a><a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Quick google searchy source: <a href="https://www.langzijn.nl/tag/langste-man-nederland" class="uri">https://www.langzijn.nl/tag/langste-man-nederland</a><a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>this explanation follows a frequentist framework of statistics. For an interesting sidestep and Bayesian credible intervals, do read this paper - <a href="http://doi.org/10.3758/s13423-015-0947-8" class="uri">http://doi.org/10.3758/s13423-015-0947-8</a><a href="#fnref5">↩</a></p></li>
</ol>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
